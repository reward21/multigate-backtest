# Multigate SQLite Explorer - Developer Documentation

Last updated: 2026-02-11

## 1) Scope

This document covers the local SQLite explorer implemented in `scripts/db_tool.py`, including:

- interactive query UI
- human-friendly trading views
- derived metrics + report/chart embedding
- local Ollama analysis
- persistent LLM memory storage
- chunked/staged LLM analysis with resumable progress

It is intended for developers extending or operating this tool.

## 2) What Was Built

The explorer now provides an end-to-end local analytics surface over backtest output:

- read-only SQL API for `runs/backtests.sqlite`
- responsive browser UI with resizable panes and scroll-safe containers
- table presets aligned to trading semantics (trades, gates, signals)
- run insights (basic + complex metrics + narrative)
- report markdown and equity chart embedding
- Ollama model discovery + analysis actions from UI
- timeout/row/context controls for local-model reliability
- persistent LLM memory in sidecar SQLite (`runs/llm_memory.sqlite`)

## 3) Runtime Architecture

### 3.1 Process model

Single-process `HTTPServer` from Python stdlib serves both API and HTML/JS UI:

- server entrypoint: `cmd_web(...)`
- handler: `DbWebHandler`
- static page generated by `_html_page()`

### 3.2 Datastores

Two SQLite connections are used in web mode:

- primary backtest DB (read-only): `connect_ro(...)`
- memory DB (read/write): `connect_rw(...)`

Design rationale:

- core trading dataset remains immutable from UI/API
- LLM memory can be written without touching backtest schema

### 3.3 UI data flow

1. UI loads and requests `/api/tables`.
2. User picks preset or edits SQL.
3. `POST /api/query` returns rows.
4. UI refreshes run insights via `/api/insights`.
5. Optional chart request via `/api/chart`.
6. Optional Ollama analysis via `/api/ollama/analyze`.
7. If enabled, analysis is persisted in memory DB and can be viewed via `/api/ollama/memory`.
8. Optional chunk pipeline stages work via `/api/ollama/stage` + process endpoints.

## 4) API Reference

### 4.1 GET `/api/tables`

Returns all non-system tables with row counts.

### 4.2 GET `/api/schema?table=<name>`

Returns `PRAGMA table_info(table)`.

### 4.3 POST `/api/query`

Body fields:

- `sql` string
- `limit` integer (optional)

Behavior:

- allows read-only SQL only (`SELECT`, `WITH`, `PRAGMA`, `EXPLAIN`)
- wraps `SELECT`/`WITH` in capped outer `LIMIT`

### 4.4 GET `/api/insights?run_id=<id>`

Returns computed run context and metrics:

- run context (vendor/dataset/schema/symbol/timeframe/data paths)
- basic derived metrics
- complex derived metrics
- narrative text
- report markdown path/content when available
- chart availability/path

### 4.5 GET `/api/chart?run_id=<id>`

Returns PNG bytes for chart path resolved from run metadata/artifacts.

### 4.6 GET `/api/ollama/models`

Returns:

- `models`
- `default_model`
- `base_url`

Default model fallback is `llama3.2:1b`.

### 4.7 POST `/api/ollama/analyze`

Body fields:

- `run_id` string (blank resolves latest run)
- `sql` string (blank means run-wide default analysis query)
- `limit` integer (default 120)
- `model` string
- `prompt` string
- `include_report` boolean (default false)
- `timeout_s` integer (default 300)
- `context_max_chars` integer (default 90000)
- `save_memory` boolean (default true)
- `analysis_mode` string (`run` or `query`; auto-resolved from SQL presence)

Success response includes:

- `answer`
- `run_id`
- query metadata (`query_row_count`, `query_elapsed_ms`, `query_columns`)
- context metadata (`context_truncated`, `context_chars`, `context_hash`)
- `memory_saved`, `memory_id`

Error behavior:

- timeouts return HTTP 504 with `ok=false`
- failures may still be stored in memory DB as error entries when `save_memory=true`

### 4.8 GET `/api/ollama/memory?run_id=<id>&limit=<n>`

Returns persisted LLM memory rows (filtered by run if provided).

### 4.9 POST `/api/ollama/stage`

Creates a chunk stage from run SQL context.

Body fields:

- `run_id`
- `sql` (optional; defaults to built-in run analysis SQL)
- `model`
- `prompt`
- `include_report`
- `timeout_s`
- `context_max_chars`
- `chunk_size`
- `max_rows`

Returns stage metadata including `stage_id`, counts, status, and progress.

### 4.10 GET `/api/ollama/stage?stage_id=<id>`

Returns one stage record with counters and computed `progress_pct`.

### 4.11 GET `/api/ollama/chunks?stage_id=<id>&limit=<n>`

Returns chunk items for a stage (queue/processed/error/running rows).

### 4.12 POST `/api/ollama/process-next`

Processes exactly one queued chunk item for `stage_id`.

### 4.13 POST `/api/ollama/process-all`

Processes up to `max_chunks` queued chunk items for `stage_id`.

## 5) Persistent Memory Schema

Database: `runs/llm_memory.sqlite`
Table: `llm_memory`

Columns:

- `memory_id` INTEGER PK AUTOINCREMENT
- `created_at_utc` TEXT
- `updated_at_utc` TEXT
- `run_id` TEXT
- `analysis_mode` TEXT
- `model` TEXT
- `user_prompt` TEXT
- `query_sql` TEXT
- `query_limit` INTEGER
- `query_row_count` INTEGER
- `include_report` INTEGER (0/1)
- `context_truncated` INTEGER (0/1)
- `context_chars` INTEGER
- `context_hash` TEXT (SHA256 of pre-truncation context payload)
- `response_markdown` TEXT
- `error_text` TEXT

Index:

- `idx_llm_memory_run_id_created` on `(run_id, created_at_utc DESC, memory_id DESC)`
- `idx_llm_memory_created` on `(created_at_utc DESC, memory_id DESC)`
- `idx_llm_memory_run_mode_created` on `(run_id, analysis_mode, created_at_utc DESC, memory_id DESC)`
- `idx_llm_memory_context_hash` on `(context_hash)`

### 5.2 Chunk Stage Tables

Table: `llm_chunk_stages`

- `stage_id` TEXT PK
- `created_at_utc`, `updated_at_utc`
- `run_id`
- `analysis_mode` (`chunk`)
- `model`
- `user_prompt`
- `base_sql`
- `include_report`
- `timeout_s`
- `context_max_chars`
- `chunk_size`
- `total_rows`
- `total_chunks`
- `processed_chunks`
- `error_chunks`
- `status` (`staged|running|completed|failed`)
- `last_error`

Table: `llm_chunk_items`

- `item_id` INTEGER PK
- `stage_id`
- `chunk_index`
- `offset_rows`
- `limit_rows`
- `row_count`
- `chunk_thumb` (mini thumbprint)
- `context_hash`
- `memory_id` (links to `llm_memory.memory_id`)
- `status` (`queued|running|processed|error`)
- `started_at_utc`, `finished_at_utc`
- `error_text`

Indexes:

- `idx_llm_chunk_items_stage_status_idx`
- `idx_llm_chunk_items_stage_thumb`
- `idx_llm_chunk_stages_run_created`

## 5.1 Memory DB Tuning

Applied in web startup (`tune_llm_memory_db(...)`):

- `PRAGMA journal_mode=WAL`
- `PRAGMA synchronous=NORMAL`
- `PRAGMA temp_store=MEMORY`
- `PRAGMA cache_size=-8000` (connection-level)

Notes:

- WAL mode persists at DB level.
- `temp_store` and `cache_size` are connection/session-level.
- Read endpoints now sort memory by `created_at_utc DESC, memory_id DESC` to align with indexes.

## 6) Configuration

### 6.1 CLI

Start web server:

```bash
python scripts/db_tool.py web --host 127.0.0.1 --port 8765
```

Custom memory DB path:

```bash
python scripts/db_tool.py web --memory-db /path/to/llm_memory.sqlite
```

### 6.2 Environment variables

- `OLLAMA_URL` default `http://127.0.0.1:11434`
- `OLLAMA_MODEL` default `llama3.2:1b`
- `OLLAMA_TIMEOUT_S` default `300`
- `OLLAMA_REPORT_MAX_CHARS` default `8000`
- `OLLAMA_CONTEXT_MAX_CHARS` default `90000`

### 6.3 Pair strategy config (multigate runner)

The backtest runner supports multi-symbol leg configuration via `config.yaml`:

```yaml
runtime:
  start_equity: 100000
  symbol_legs:
    - symbol: TSLA
      data_path: data/ingested/databento/tsla/xnas-ohlcv-1m/tsla-xnas-itch-ohlcv-1m.parquet
      bias: short_only
    - symbol: SPY
      data_path: data/ingested/databento/spy/arcx-ohlcv-1m/spy-arcx-pillar-ohlcv-1m.parquet
      bias: long_only
```

Supported `bias` values:

- `short_only`
- `short_heavy`
- `long_only`
- `long_heavy`

## 7) UI Behavior Notes

### 7.1 Layout and responsiveness

- page spans full viewport width
- left pane is resizable with drag splitter and buttons
- query editor and result table heights are user-resizable
- workspace supports both x/y scrolling where needed
- text-heavy boxes wrap + scroll (`schema`, JSON/text outputs, reports)

### 7.2 Human views

Human views are SQL templates that map raw schema to readable trading semantics:

- `Trades (Detailed)`
- `Trade Gate Matrix`
- `Trade Denials Timeline`
- `Trades Pass (by Gate)`
- `Signals (Detailed)`

### 7.3 Ollama panel

Controls:

- model selection from discovered tags
- row cap and timeout tuning
- report-context toggle
- save-memory toggle
- load-memory action for current run
- chunk pipeline controls: `Chunk`, `MaxRows`, `Batch`, `Stage Chunks`, `Process Next`, `Process Batch`, `Refresh Stage`, `Stage ID`
- progress bar + stage log for chunk execution telemetry

Chunk behavior:

- stage creation snapshots SQL and row count
- chunk items are queued with `LIMIT/OFFSET` partitions
- each processed chunk writes one memory row (`analysis_mode=chunk`)
- stage counters are refreshed after each chunk
- stages are resumable by `stage_id`

## 8) Guardrails and Safety

- primary DB access is read-only in server process
- SQL write operations are blocked by `_is_safe_readonly_sql`
- analyze endpoint constrains row limits, timeout bounds, and context size
- model output is treated as advisory text, not as authoritative strategy logic

## 9) Troubleshooting

### 9.1 Ollama timeouts

Symptoms:

- `{"ok": false, "error": "timed out"}` or timeout text in UI

Actions:

- lower `Rows` to `20-60`
- disable `include report excerpt`
- increase `Timeout(s)` to `300-600`
- use `llama3.2:1b` for faster iteration

### 9.2 High CPU / perceived freeze

Local inference can saturate CPU on long prompts/context.

Actions:

- run one analysis at a time
- reduce context size and rows
- confirm no overlapping requests from multiple tabs

### 9.3 Empty model list

Actions:

- verify `curl http://127.0.0.1:11434/api/tags`
- verify `OLLAMA_URL`
- ensure Ollama app/server is running and reachable

### 9.4 Memory endpoint unavailable

If `/api/ollama/memory` returns memory-not-configured:

- restart UI via `scripts/db_tool.py web`
- check write permission for memory DB directory

### 9.5 Memory DB inspection and performance checks

Check health:

```bash
sqlite3 runs/llm_memory.sqlite "SELECT COUNT(*) AS rows_total, SUM(CASE WHEN error_text<>'' THEN 1 ELSE 0 END) AS error_rows, MIN(created_at_utc) AS first_row, MAX(created_at_utc) AS last_row FROM llm_memory;"
```

Check journal/index state:

```bash
sqlite3 runs/llm_memory.sqlite "PRAGMA journal_mode; PRAGMA synchronous; PRAGMA index_list('llm_memory');"
```

Check query plans:

```bash
sqlite3 runs/llm_memory.sqlite "EXPLAIN QUERY PLAN SELECT memory_id, created_at_utc FROM llm_memory WHERE run_id='YOUR_RUN_ID' ORDER BY created_at_utc DESC, memory_id DESC LIMIT 20;"
sqlite3 runs/llm_memory.sqlite "EXPLAIN QUERY PLAN SELECT memory_id, created_at_utc FROM llm_memory ORDER BY created_at_utc DESC, memory_id DESC LIMIT 20;"
```

## 10) Extension Points

- Add endpoint to fetch full memory record by `memory_id`.
- Add export endpoint for markdown/JSON memory bundles.
- Add grounding mode for strict evidence-backed summaries.
- Add async job queue if long inference throughput becomes a bottleneck.
- Add UI compare mode between two memory entries for same run.

## 11) Operational Checklist

Before demoing or running sessions:

1. Start web server and confirm `http://127.0.0.1:8765` loads.
2. Confirm model discovery in Ollama panel.
3. Run one analysis with low row cap first.
4. Verify a memory row is created and visible with `Load Memory`.
5. Confirm report/chart render for selected run.
